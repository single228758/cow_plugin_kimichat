import re
import logging
import requests
import time
import os
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, urlencode

logger = logging.getLogger(__name__)

class MediaParser:
    def __init__(self, config=None):
        """åˆå§‹åŒ–è§£æå™¨
        Args:
            config: é…ç½®ä¿¡æ¯å­—å…¸
        """
        self.config = config or {}
        
        # è®¾ç½®ä¸‹è½½ç›®å½•
        self.temp_dir = os.path.join('plugins', 'cow_plugin_kimichat', 'storage', 'temp')
        if not os.path.exists(self.temp_dir):
            os.makedirs(self.temp_dir)
            
        # åˆå§‹åŒ–çº¿ç¨‹æ± 
        self.executor = ThreadPoolExecutor(max_workers=5)
        
        # æ”¯æŒçš„å¹³å°å’Œå¯¹åº”çš„åŸŸå
        self.platforms = {
            "douyin": ["douyin.com", "iesdouyin.com"],
            "kuaishou": ["kuaishou.com", "gifshow.com"],
            "weibo": ["weibo.com", "weibo.cn"],
            "xiaohongshu": ["xiaohongshu.com", "xhslink.com"]
        }

    def extract_share_info(self, content):
        """ä»åˆ†äº«å†…å®¹ä¸­æå–æ ‡é¢˜å’ŒURL
        Args:
            content: åˆ†äº«å†…å®¹æ–‡æœ¬
        Returns:
            tuple: (æ ‡é¢˜, URL)
        """
        try:
            # æå–æ ‡é¢˜
            title = ""
            title_match = re.search(r'ã€(.+?)ã€‘', content)
            if title_match:
                title = title_match.group(1)
            
            # æå–URL
            url = None
            url_pattern = r'https?://[^\s<>"]+|www\.[^\s<>"]+(?:\?[^\s<>"]*)?(?:#[^\s<>"]*)?'
            url_match = re.search(url_pattern, content)
            if url_match:
                url = url_match.group(0)
            
            return title, url
            
        except Exception as e:
            logger.error(f"[MediaParser] è§£æåˆ†äº«å†…å®¹å¤±è´¥: {e}")
            return None, None

    def is_video_share(self, content):
        """åˆ¤æ–­æ˜¯å¦æ˜¯è§†é¢‘åˆ†äº«å†…å®¹
        Args:
            content: å¾…æ£€æŸ¥çš„æ–‡æœ¬å†…å®¹
        Returns:
            bool: æ˜¯å¦æ˜¯è§†é¢‘åˆ†äº«
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¹³å°ç‰¹å¾
        platform_patterns = [
            r'å¤åˆ¶æ‰“å¼€æŠ–éŸ³',
            r'å¿«æ‰‹é“¾æ¥',
            r'å¾®åšè§†é¢‘',
            r'å°çº¢ä¹¦è§†é¢‘'
        ]
        
        for pattern in platform_patterns:
            if re.search(pattern, content):
                return True
                
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ”¯æŒçš„åŸŸå
        for platform in self.platforms.values():
            for domain in platform:
                if domain in content:
                    return True
                    
        return False

    def get_video_info(self, url):
        """è·å–è§†é¢‘ä¿¡æ¯
        Args:
            url: è§†é¢‘é“¾æ¥
        Returns:
            dict: åŒ…å«è§†é¢‘ä¿¡æ¯çš„å­—å…¸,å¦‚æœå‡ºé”™è¿”å›None
        """
        try:
            # å®šä¹‰ä¸¤ä¸ªAPIçš„é…ç½®
            apis = [
                {
                    "url": "https://www.hhlqilongzhu.cn/api/sp_jx/sp.php",
                    "params": {"url": url},
                    "timeout": 3,  # ç¬¬ä¸€ä¸ªAPIè®¾ç½®3ç§’è¶…æ—¶
                    "parser": self._parse_api1_response
                },
                {
                    "url": "https://api.yujn.cn/api/dy_jx.php",
                    "params": {"msg": url},
                    "timeout": 10,  # ç¬¬äºŒä¸ªAPIç»™æ›´é•¿çš„è¶…æ—¶æ—¶é—´
                    "parser": self._parse_api2_response
                }
            ]

            # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
            futures = []
            with ThreadPoolExecutor(max_workers=2) as executor:
                for api in apis:
                    future = executor.submit(
                        self._make_request,
                        api["url"],
                        params=api["params"],
                        timeout=api["timeout"]
                    )
                    futures.append((future, api))

                # ç­‰å¾…ç¬¬ä¸€ä¸ªå®Œæˆçš„ä»»åŠ¡
                for future, api in futures:
                    try:
                        response = future.result(timeout=api["timeout"])
                        if response and response.status_code == 200:
                            try:
                                # ä½¿ç”¨å¯¹åº”çš„è§£æå™¨å¤„ç†å“åº”
                                result = api["parser"](response)
                                if result:
                                    return result
                            except Exception as e:
                                logger.warning(f"[MediaParser] APIè§£æå¤±è´¥: {e}")
                                continue
                    except Exception as e:
                        logger.warning(f"[MediaParser] APIè¯·æ±‚å¤±è´¥: {e}")
                        continue

            logger.error("[MediaParser] æ‰€æœ‰APIéƒ½å¤±è´¥")
            return None

        except Exception as e:
            logger.error(f"[MediaParser] è·å–è§†é¢‘ä¿¡æ¯å¼‚å¸¸: {e}", exc_info=True)
            return None

    def _parse_api1_response(self, response):
        """è§£æç¬¬ä¸€ä¸ªAPIçš„å“åº”"""
        try:
            data = response.json()
            if data.get("code") == 200:
                video_data = data.get("data")
                if video_data and isinstance(video_data, dict):
                    video_url = video_data.get("url")
                    if video_url:
                        video_path = None
                        try:
                            video_path = self.download_video(video_url)
                        except Exception as e:
                            logger.warning(f"[MediaParser] è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")

                        return {
                            "title": video_data.get("title", ""),
                            "author": video_data.get("author", ""),
                            "play_url": video_url,
                            "video_url": video_url,
                            "video_path": video_path,
                            "platform": self.get_platform(video_url)
                        }
        except Exception as e:
            logger.warning(f"[MediaParser] è§£æç¬¬ä¸€ä¸ªAPIå“åº”å¤±è´¥: {e}")
        return None

    def _parse_api2_response(self, response):
        """è§£æç¬¬äºŒä¸ªAPIçš„å“åº”"""
        try:
            data = response.json()
            if "msg" in data and data["msg"] == "è§£ææˆåŠŸï¼ğŸ’¬ï¸":
                video_url = data.get("video")
                if video_url:
                    video_path = None
                    try:
                        video_path = self.download_video(video_url)
                    except Exception as e:
                        logger.warning(f"[MediaParser] è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")

                    return {
                        "title": data.get("title", ""),
                        "author": data.get("name", ""),
                        "play_url": video_url,
                        "video_url": video_url,
                        "video_path": video_path,
                        "platform": self.get_platform(video_url)
                    }
        except Exception as e:
            logger.warning(f"[MediaParser] è§£æç¬¬äºŒä¸ªAPIå“åº”å¤±è´¥: {e}")
        return None

    def download_video(self, url):
        """ä¸‹è½½è§†é¢‘
        Args:
            url: è§†é¢‘URL
        Returns:
            str: è§†é¢‘æœ¬åœ°è·¯å¾„,ä¸‹è½½å¤±è´¥è¿”å›None
        """
        try:
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            filename = f"video_{int(time.time())}.mp4"
            filepath = os.path.join(self.temp_dir, filename)
            
            # ä¸‹è½½è§†é¢‘
            response = requests.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            # æ£€æŸ¥å“åº”å¤´
            content_type = response.headers.get("Content-Type")
            if content_type and not content_type.startswith("video/"):
                logger.warning(f"[MediaParser] ä¸‹è½½çš„æ–‡ä»¶å¯èƒ½ä¸æ˜¯è§†é¢‘: {content_type}")
            
            # å†™å…¥æ–‡ä»¶
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        
            logger.info(f"[MediaParser] è§†é¢‘ä¸‹è½½æˆåŠŸ: {filepath}")
            return filepath
            
        except requests.RequestException as e:
            logger.error(f"[MediaParser] è§†é¢‘ä¸‹è½½è¯·æ±‚å¼‚å¸¸: {e}")
        except IOError as e:
            logger.error(f"[MediaParser] è§†é¢‘å†™å…¥æ–‡ä»¶å¼‚å¸¸: {e}")
        except Exception as e:
            logger.error(f"[MediaParser] è§†é¢‘ä¸‹è½½å¼‚å¸¸: {e}", exc_info=True)
        
        return None

    def get_platform(self, url):
        """è·å–å¹³å°æ ‡è¯†
        Args:
            url: è§†é¢‘URL
        Returns:
            str: å¹³å°æ ‡è¯†
        """
        domain = urlparse(url).netloc
        
        for platform, domains in self.platforms.items():
            if any(d in domain for d in domains):
                return platform
                
        return "unknown"

    def _make_request(self, url, params=None, headers=None, max_retries=3, timeout=3):
        """å‘é€HTTPè¯·æ±‚
        Args:
            url: è¯·æ±‚URL
            params: è¯·æ±‚å‚æ•°
            headers: è¯·æ±‚å¤´
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
        Returns:
            Response: è¯·æ±‚å“åº”å¯¹è±¡,å¦‚æœè¯·æ±‚å¤±è´¥è¿”å›None
        """
        headers = headers or {}
        headers["User-Agent"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
        
        for i in range(max_retries):
            try:
                response = requests.get(
                    url,
                    params=params,
                    headers=headers,
                    timeout=timeout  # ä½¿ç”¨ä¼ å…¥çš„è¶…æ—¶æ—¶é—´
                )
                response.raise_for_status()
                return response
            except (requests.RequestException, requests.Timeout) as e:
                logger.warning(f"[MediaParser] è¯·æ±‚å¤±è´¥({i+1}/{max_retries}): {e}")
                if i == max_retries - 1:
                    logger.error("[MediaParser] è¯·æ±‚å¤šæ¬¡å¤±è´¥,æ”¾å¼ƒé‡è¯•")
                    return None
                time.sleep(0.5)  # å‡å°‘é‡è¯•ç­‰å¾…æ—¶é—´